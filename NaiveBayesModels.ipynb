{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix#, ConfusionMatrixDisplay\n",
    "import seaborn as sb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import pickle\n",
    "from scipy.sparse import save_npz, load_npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"issues.csv\")\n",
    "type_list = df.issue_type.to_list()\n",
    "priority_list = df.priority.to_list()\n",
    "mat = load_npz('matrix.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge other features to matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models on different data sets or with different labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_classes = ['Improvement', 'Bug', 'New Feature', 'Task', 'Sub-task']\n",
    "models = [\"MultinomialNB\", \"GaussianNB\", \"SVM\"]\n",
    "\n",
    "# use_given_types: uses labels from type_list instead of only the relevant_classes, use this\n",
    "# if you want to check how the models perfoms on all classes (worse) or when the loaded data comes from\n",
    "def build_model_from_files(name_extension, use_given_types = False, use_all_features = True, model = \"MultinomialNB\"):\n",
    "    df = pd.read_csv('issues'+name_extension+'.csv')\n",
    "    mat = load_npz('matrix'+name_extension+'.npz')\n",
    "    type_list = df.issue_type.to_list()\n",
    "    if  not use_given_types:\n",
    "        type_list = [t if t in relevant_classes else 'Other' for t in type_list]\n",
    "    priority_list = df.priority.to_list()\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(mat, type_list, test_size=0.1, random_state=1234)\n",
    "    \n",
    "    if model == \"MultinomialNB\":\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(X_train, y_train)\n",
    "    elif model == \"GaussianNB\":\n",
    "        clf = GaussianNB()\n",
    "        clf.fit(X_train.toarray(), y_train)\n",
    "    elif model == \"SVM\":\n",
    "        clf = SVC(gamma='auto')\n",
    "        clf.fit(X_train, y_train)\n",
    "    train_predicted= clf.predict(X_train.toarray())\n",
    "    test_predicted = clf.predict(X_test.toarray())\n",
    "    \n",
    "    print(model + \" Training accuracy:\", metrics.accuracy_score(y_train, train_predicted))\n",
    "    print(model + \" Test accuracy:\",metrics.accuracy_score(y_test, test_predicted))\n",
    "    confusion = confusion_matrix(y_test, test_predicted)\n",
    "    #ConfusionMatrixDisplay(confusion, binary_types)\n",
    "    print(confusion)\n",
    "    \n",
    "    y_binary_train  = [y if y == 'Bug' else 'Other' for y in y_train]\n",
    "    y_binary_test = [y if y == 'Bug' else 'Other' for y in y_test]\n",
    "    if model == \"MultinomialNB\":\n",
    "        binary_model = MultinomialNB().fit(X_train, y_binary_train)\n",
    "    elif model == \"GaussianNB\":\n",
    "        binary_model = GaussianNB().fit(X_train.toarray(), y_binary_train)\n",
    "    elif model == \"SVM\":\n",
    "        binary_model = SVC(gamma='auto').fit(X_train, y_binary_train)\n",
    "        \n",
    "        \n",
    "    train_binary_predicted = binary_model.predict(X_train.toarray())\n",
    "    test_binary_predicted = binary_model.predict(X_test.toarray())\n",
    "    \n",
    "    print(model + \" Training accuracy (on binary data):\",metrics.accuracy_score(y_binary_train, train_binary_predicted))\n",
    "    print(model + \" Test accuracy (on binary data):\",metrics.accuracy_score(y_binary_test, test_binary_predicted))\n",
    "    binary_confusion = confusion_matrix(y_binary_test, test_binary_predicted)\n",
    "    #ConfusionMatrixDisplay(confusion, binary_types)\n",
    "    print(binary_confusion)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB Training accuracy: 0.16510644918704456\n",
      "GaussianNB Test accuracy: 0.14469078179696615\n",
      "[[282  73 356 461 741 228]\n",
      " [ 24  22 247 203 616 125]\n",
      " [  3   0  85  44 159  20]\n",
      " [  0   3  14  32  52  12]\n",
      " [  1   1  17  17 133  12]\n",
      " [  3   3  19  23 188  66]]\n",
      "GaussianNB Training accuracy (on binary data): 0.6560692892150507\n",
      "GaussianNB Test accuracy (on binary data): 0.6387397899649941\n",
      "[[ 778 1363]\n",
      " [ 185 1959]]\n"
     ]
    }
   ],
   "source": [
    "# old model\n",
    "build_model_from_files('', model=\"GaussianNB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(name_extension, use_given_types = False, use_all_features = True, random_state = 1234, splits=10):\n",
    "    df = pd.read_csv('issues'+name_extension+'.csv')\n",
    "    mat = load_npz('matrix'+name_extension+'.npz')\n",
    "    type_list = df.issue_type.to_list()\n",
    "    if not use_given_types:\n",
    "        type_list = [t if t in relevant_classes else 'Other' for t in type_list]\n",
    "    priority_list = df.priority.to_list()\n",
    "    \n",
    "    kf = KFold(n_splits = splits)\n",
    "    kf.random_state = 1234\n",
    "    kf.shuffle = True\n",
    "    kf.get_n_splits(mat)\n",
    "    \n",
    "    whole_data_accuracy = []\n",
    "    binary_data_accuracy = []\n",
    "    \n",
    "    for train, test in kf.split(mat):\n",
    "        X_train, X_test, y_train, y_test = mat[train], mat[test], [type_list[x] for x in train], [type_list[x] for x in test]\n",
    "        clf = MultinomialNB().fit(X_train, y_train)\n",
    "        predicted= clf.predict(X_test)\n",
    "        whole_data_accuracy.append(metrics.accuracy_score(y_test, predicted))\n",
    "        y_binary_train  = [y if y == 'Bug' else 'Other' for y in y_train]\n",
    "        y_binary_test = [y if y == 'Bug' else 'Other' for y in y_test]\n",
    "        binary_model = MultinomialNB().fit(X_train, y_binary_train)\n",
    "        binary_predicted = binary_model.predict(X_test)\n",
    "        binary_data_accuracy.append(metrics.accuracy_score(y_binary_test, binary_predicted))\n",
    "    return np.array(whole_data_accuracy), np.array(binary_data_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split = 5; mean accuracy (all data): 0.6036220628127794; mean accuracy (binary data): 0.7635362633181696\n",
      "Split = 6; mean accuracy (all data): 0.6039722138640019; mean accuracy (binary data): 0.7639565111721356\n",
      "Split = 7; mean accuracy (all data): 0.6038788272780259; mean accuracy (binary data): 0.7638397915340672\n",
      "Split = 8; mean accuracy (all data): 0.603575429424944; mean accuracy (binary data): 0.7635828976848393\n",
      "Split = 9; mean accuracy (all data): 0.604252141240169; mean accuracy (binary data): 0.7643296834241643\n",
      "Split = 10; mean accuracy (all data): 0.6041820967982681; mean accuracy (binary data): 0.7645632714384859\n",
      "Split = 11; mean accuracy (all data): 0.6036688766129183; mean accuracy (binary data): 0.7642601320887598\n",
      "Split = 12; mean accuracy (all data): 0.6042756176492813; mean accuracy (binary data): 0.7641431416214391\n",
      "Split = 13; mean accuracy (all data): 0.6033187079910382; mean accuracy (binary data): 0.7640730022404779\n",
      "Split = 14; mean accuracy (all data): 0.6037386096766921; mean accuracy (binary data): 0.7645399137548953\n",
      "Split = 15; mean accuracy (all data): 0.6035055102428324; mean accuracy (binary data): 0.7643067774303748\n",
      "Split = 16; mean accuracy (all data): 0.6037387976101568; mean accuracy (binary data): 0.7646564600448096\n",
      "Split = 17; mean accuracy (all data): 0.6036688455628185; mean accuracy (binary data): 0.7643306218428134\n",
      "Split = 18; mean accuracy (all data): 0.6037388762028681; mean accuracy (binary data): 0.7643539384114278\n",
      "Split = 19; mean accuracy (all data): 0.6038321584732695; mean accuracy (binary data): 0.7643067456583148\n",
      "Split = 20; mean accuracy (all data): 0.603972251523101; mean accuracy (binary data): 0.7648675382425487\n"
     ]
    }
   ],
   "source": [
    "for i in range(5, 21):\n",
    "    whole, binary = cross_validation('', use_given_types = False, use_all_features = True, random_state = 12345, splits=i)\n",
    "    print(\"Split = \"+ str(i) +\"; mean accuracy (all data): \" + str(np.mean(whole)) + \"; mean accuracy (binary data): \" + str(np.mean(binary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy: 0.6098729930505632\n",
      "[[1852  210    0    9    2]\n",
      " [ 587  657    2    1   12]\n",
      " [ 137  206    7    0    1]\n",
      " [  95   70    1   12    4]\n",
      " [ 154  132    0    5   17]]\n",
      "MultinomialNB Accuracy (on binary data): 0.7620416966211359\n",
      "[[1515  558]\n",
      " [ 435 1665]]\n"
     ]
    }
   ],
   "source": [
    "# 'Other' issues have been discarded\n",
    "build_model_from_files('_reduced', use_given_types = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy: 0.6111636707663197\n",
      "[[1831  204    0    6    5    0]\n",
      " [ 587  715    3    2   13    0]\n",
      " [ 122  196    2    1    1    0]\n",
      " [  90   89    0   19    6    0]\n",
      " [ 142  114    0    9   17    0]\n",
      " [  25   29    0    0    0    0]]\n",
      "MultinomialNB Accuracy (on binary data): 0.772469252601703\n",
      "[[1510  536]\n",
      " [ 426 1756]]\n"
     ]
    }
   ],
   "source": [
    "# 'Other' issues have been discarded but uses class 'Wish' in addition to relevant_classes\n",
    "build_model_from_files('_reduced_plus_wish', use_given_types = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy: 0.5873978996499416\n",
      "[[1940  183    0    1    7   10]\n",
      " [ 686  545    0    0    3    3]\n",
      " [ 133  170    2    0    5    1]\n",
      " [  62   48    0    0    0    3]\n",
      " [ 101   59    0    0   19    2]\n",
      " [ 170  108    1    0   12   11]]\n",
      "MultinomialNB Accuracy (on binary data): 0.7409568261376897\n",
      "[[1547  594]\n",
      " [ 516 1628]]\n"
     ]
    }
   ],
   "source": [
    "# builds method based on new text processing method\n",
    "build_model_from_files('_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO model where code has not been removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model aggregation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
